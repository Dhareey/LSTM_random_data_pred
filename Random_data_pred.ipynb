{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRELUDE ###\n",
    "In this algorithm, i will run a Long-Short-Term- Memory model on a truely random data. The data is a random powerball game data downloaded online. I will run the LSTM model to predict the next powerball number.\n",
    "<p> The architecture is pretty simple. Convert the powerball numbes into one-hot encoded value of all possible values, pass the encoded data into a 2-layered LSTM connected to a fully connected layer to predict the powerball number. <p> To split the task, i'll make the predicton in two ways\n",
    "    <ul>\n",
    "        <li>Predict whether the next powerball number will be odd or even</li>\n",
    "        <li> Predict the exact number of the next powerball number </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv('data/powerball_dataT.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = data_csv[['Pevodd', 'PowerBall']]\n",
    "data_csv.dropna(axis =0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['even', 'odd'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv['Pevodd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 3, 1, 2, 6, 7, 4, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv['PowerBall'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv['z'] = data_csv['Pevodd'].apply(lambda x: 0. if x=='even' else 1.)\n",
    "data_csv= data_csv.astype({'PowerBall': 'int32', 'z':'int32'})\n",
    "z_data = list(data_csv['z'][1:])\n",
    "z_data.append(data_csv['z'][0])\n",
    "x_data = list(data_csv['PowerBall'])\n",
    "y_data = x_data[1:]\n",
    "y_data.append(x_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(set(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745450 745450 745450\n"
     ]
    }
   ],
   "source": [
    "print(len(x_data), len(y_data), len(z_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test = np.array(x_data[:600000]), np.array(x_data[600000:672725]), np.array(x_data[672725:])\n",
    "y_train, y_valid, y_test = np.array(y_data[:600000]), np.array(y_data[600000:672725]), np.array(y_data[672725:])\n",
    "z_train, z_valid, z_test = np.array(z_data[:600000]), np.array(z_data[600000:672725]), np.array(z_data[672725:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_valid), torch.from_numpy(y_valid))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "z_train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(z_train))\n",
    "z_valid_data = TensorDataset(torch.from_numpy(x_valid), torch.from_numpy(z_valid))\n",
    "z_test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size= 120\n",
    "seq_length= 100\n",
    "batch= batch_size * seq_length\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch, drop_last = True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch, drop_last= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(arr, cols_num):\n",
    "    \"\"\"\n",
    "    This function takes in an pytorch dataloader object and returns a one-hot encoded array with dimensions of array x n_labels.\n",
    "    E.G if it takes an array of [3,2,1] and n_labels of 8, it returns a 3x3(array_size by cols_num) hot encoded array like so\n",
    "    [[0 0 1 0 0 0 0 0]\n",
    "    [0 1 0 0 0 0 0 0]\n",
    "    [1 0 0 0 0 0 0 0]]\n",
    "    \"\"\"\n",
    "    array = np.array(arr)\n",
    "    # First, create an array.size by cols_num array of zeros in float\n",
    "    one_hot = np.zeros((array.size,cols_num), dtype= np.float32)\n",
    "    \n",
    "    # Fill a \"1\" to each row based on the value in array\n",
    "    one_hot[np.arange(one_hot.shape[0]), array.flatten()] = 1.\n",
    "    \n",
    "    # Return back to the original shape\n",
    "    one_hot = one_hot.reshape((*array.shape, cols_num))\n",
    "    return torch.from_numpy(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "dataiter= iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "validiter = iter(valid_loader)\n",
    "valid_x, valid_y = dataiter.next()\n",
    "\n",
    "print(oneHotEncode(sample_x, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dude, dont try it, your pc is gonna crash\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if (train_on_gpu):\n",
    "  print('Yaay, CUDA is available, now you can train')\n",
    "else:\n",
    "  print('Dude, dont try it, your pc is gonna crash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yorLSTM(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden, n_layers=2,drop_prob=0.5,lr= 0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden= n_hidden\n",
    "        self.lr = lr\n",
    "            \n",
    "        #Data entered\n",
    "        self.chars = tuple(set(tokens))\n",
    "            \n",
    "        # Define model layers\n",
    "        self.lstm = nn.LSTM(len(self.chars), self.n_hidden, self.n_layers,dropout=drop_prob,batch_first=True)\n",
    "            \n",
    "        # Dropout in between layers\n",
    "        self.dropout =nn.Dropout(drop_prob)\n",
    "            \n",
    "        # Connect to a fully connected layer\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars))\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        # Dropout to avoid overfitting\n",
    "        out= self.dropout(out)\n",
    "        \n",
    "        # Reshape for fully connected layer\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        # Pass through a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        #return out, hidden\n",
    "        return out, hidden\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initialize the weight and hidden value\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda(),\n",
    "                      weight.new(self.n_layers,batch_size,self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers,batch_size,self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network,training_data, validation_data, epochs, batch_size,lr, seq_length, clip=5, vis=10):\n",
    "    # Set the RNN network to train\n",
    "    network.train()\n",
    "    \n",
    "    #Set the optimiser and calculate the loss\n",
    "    optimiser = torch.optim.Adam(network.parameters(), lr= lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Run on CUDA if available\n",
    "    if (train_on_gpu):\n",
    "        network.cuda()\n",
    "        \n",
    "    counter = 0\n",
    "    # set total number of characters\n",
    "    n_chars = len(network.chars)\n",
    "    \n",
    "    # Train in range of epochs\n",
    "    for i in range(epochs):\n",
    "        # initialise the hidden state\n",
    "        h = network.init_hidden(batch_size)\n",
    "        for x, y in training_data:\n",
    "            counter+=1\n",
    "            \n",
    "            # One-Hot-Encode the training data\n",
    "            x = oneHotEncode(x.reshape(batch_size,seq_length), n_chars)\n",
    "            \n",
    "            # If on Cuda, cnvert the x and y to cuda\n",
    "            if (train_on_gpu):\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "            \n",
    "            # Set accumulated gradient to zero\n",
    "            network.zero_grad()\n",
    "            \n",
    "            output, h = network(x, h)\n",
    "            \n",
    "            # Calculate the loss and back propagate\n",
    "            loss = criterion(output, y.view(batch_size*seq_length).long())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(network.parameters(), clip)\n",
    "            optimiser.step()\n",
    "            \n",
    "            # Calculate validation loss at every 10 iteration\n",
    "            if counter% vis == 0:\n",
    "                # Initialise the hidden state\n",
    "                val_h = network.init_hidden(batch_size)\n",
    "                validation_losses = []\n",
    "                \n",
    "                #set network to evalution\n",
    "                network.eval()\n",
    "                \n",
    "                for x,y in validation_data:\n",
    "                    x = oneHotEncode(x.reshape(batch_size,seq_length), n_chars)\n",
    "                    \n",
    "                    if (train_on_gpu):\n",
    "                        x,y = x.cuda(), y.cuda()\n",
    "                    val_h = tuple([each for each in val_h])\n",
    "                    \n",
    "                    output, val_h = network(x, val_h)\n",
    "                    \n",
    "                    #Calculate the loss\n",
    "                    loss = criterion(output, y.view(batch_size* seq_length).long())\n",
    "                    \n",
    "                    # Append loss to validation losses\n",
    "                    validation_losses.append(loss.item())\n",
    "                    \n",
    "                    # Set network back to training\n",
    "                    network.train()\n",
    "                    \n",
    "                    print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(validation_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yorLSTM(\n",
      "  (lstm): LSTM(10, 500, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LSTM Model\n",
    "n_hidden = 500\n",
    "\n",
    "network = yorLSTM(x_data,n_hidden)\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate the training\n",
    "epochs = 40\n",
    "lr = 0.001\n",
    "train(network,train_loader,valid_loader,epochs,batch_size,lr,seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, char, h= None, top_k= None):\n",
    "    # tensor inputs\n",
    "    inputs = torch.from_numpy(x)\n",
    "\n",
    "    inputs = oneHotEncode(inputs, len(network.chars))\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = network(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(network.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return char, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(network, size, prime, top_k=None):\n",
    "        \n",
    "    if(train_on_gpu):\n",
    "        network.cuda()\n",
    "    else:\n",
    "        network.cpu()\n",
    "    \n",
    "    network.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = prime\n",
    "    h = network.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(network, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(network, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return chars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
